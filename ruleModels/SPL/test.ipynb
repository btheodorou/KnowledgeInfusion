{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('linear1', Linear(in_features=768, out_features=256, bias=True)), ('relu1', ReLU())]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpt3/code/KnowledgeInfusion/ruleModels/SPL/hmc-utils/GatingFunction.py:61: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from common import *\n",
    "from model import HALOModel\n",
    "from config import HALOConfig\n",
    "\n",
    "# Circuit imports\n",
    "import sys\n",
    "sys.path.append(os.path.join(sys.path[0],'hmc-utils'))\n",
    "sys.path.append(os.path.join(sys.path[0],'hmc-utils', 'pypsdd'))\n",
    "from GatingFunction import DenseGatingFunction\n",
    "from compute_mpe import CircuitMPE\n",
    "\n",
    "RUNS = 1\n",
    "\n",
    "config = HALOConfig()\n",
    "NUM_GENERATIONS = 10000\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create circuit object\n",
    "cmpe = CircuitMPE('constraints/inpatient.vtree', 'constraints/inpatient.sdd')\n",
    "\n",
    "# Create gating function\n",
    "gate = DenseGatingFunction(cmpe.beta, gate_layers=[config.n_embd] + [256]*config.num_gates, num_reps=config.num_reps).to(device)\n",
    "\n",
    "# Create the model\n",
    "model = HALOModel(config).to(device)\n",
    "\n",
    "state = torch.load('../../save/spl_model_old')\n",
    "model.load_state_dict(state['model'])\n",
    "gate.load_state_dict(state['gate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sequence(model, length, context, batch_size, device='cuda', sample=True):\n",
    "  context = torch.tensor(context, device=device, dtype=torch.float32).unsqueeze(0).repeat(batch_size, 1)\n",
    "  prev = context.unsqueeze(1)\n",
    "  context = None\n",
    "  with torch.no_grad():\n",
    "    for _ in range(length-1):\n",
    "      next = model.sample(prev)\n",
    "      theta = gate(next)\n",
    "      cmpe.set_params(theta)\n",
    "      res = cmpe.get_mpe_inst(next.size(0))\n",
    "      next = (res > 0).float()\n",
    "      prev = torch.cat((prev, next.unsqueeze(1)), dim=1)\n",
    "      \n",
    "      if torch.sum(torch.sum(prev[:,:,config.code_vocab_size+config.label_vocab_size+1], dim=1).bool().int(), dim=0).item() == batch_size:\n",
    "        break\n",
    "  ehr = prev.cpu().detach().numpy()\n",
    "  prev = None\n",
    "  return ehr\n",
    "\n",
    "def convert_ehr(ehrs, index_to_code=None):\n",
    "  ehr_outputs = []\n",
    "  for i in range(len(ehrs)):\n",
    "    ehr = ehrs[i]\n",
    "    ehr_output = []\n",
    "    labels_output = ehr[1][config.code_vocab_size:config.code_vocab_size+config.label_vocab_size]\n",
    "    if index_to_code is not None:\n",
    "      labels_output = [index_to_code[idx + config.code_vocab_size] for idx in np.nonzero(labels_output)[0]]\n",
    "    for j in range(2, len(ehr)):\n",
    "      visit = ehr[j]\n",
    "      visit_output = []\n",
    "      indices = np.nonzero(visit)[0]\n",
    "      end = False\n",
    "      for idx in indices:\n",
    "        if idx < config.code_vocab_size: \n",
    "          visit_output.append(index_to_code[idx] if index_to_code is not None else idx)\n",
    "        elif idx == config.code_vocab_size+config.label_vocab_size+1:\n",
    "          end = True\n",
    "      if visit_output != []:\n",
    "        ehr_output.append(visit_output)\n",
    "      if end:\n",
    "        break\n",
    "    ehr_outputs.append({'visits': ehr_output, 'labels': labels_output})\n",
    "  ehr = None\n",
    "  ehr_output = None\n",
    "  labels_output = None\n",
    "  visit = None\n",
    "  visit_output = None\n",
    "  indices = None\n",
    "  return ehr_outputs\n",
    "\n",
    "# Generate Synthetic EHR dataset\n",
    "speeds = []\n",
    "stoken = np.zeros(config.total_vocab_size)\n",
    "stoken[config.code_vocab_size+config.label_vocab_size] = 1\n",
    "for run in tqdm(range(RUNS)):\n",
    "  SEED = run\n",
    "  random.seed(SEED)\n",
    "  np.random.seed(SEED)\n",
    "  torch.manual_seed(SEED)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    \n",
    "  synthetic_ehr_dataset = []\n",
    "  start = time()\n",
    "  for i in tqdm(range(0, NUM_GENERATIONS, config.sample_batch_size), leave=False):\n",
    "    bs = min([NUM_GENERATIONS-i, config.sample_batch_size])\n",
    "    batch_synthetic_ehrs = sample_sequence(model, config.n_ctx, stoken, batch_size=bs, device=device, sample=True)\n",
    "    batch_synthetic_ehrs = convert_ehr(batch_synthetic_ehrs)\n",
    "    synthetic_ehr_dataset += batch_synthetic_ehrs\n",
    "  end = time()\n",
    "\n",
    "  generationTime = end - start\n",
    "  secondsPerPatient = generationTime / NUM_GENERATIONS\n",
    "  speeds.append(secondsPerPatient)\n",
    "  pickle.dump(secondsPerPatient, open(f'../../results/generationSpeeds/splSpeed_{run}.pkl', 'wb'))\n",
    "  pickle.dump(synthetic_ehr_dataset, open(f'../../results/splDataset_{run}.pkl', 'wb'))\n",
    "print(f\"Seconds Per Patient: {np.mean(speeds)} +/- {np.std(speeds) / np.sqrt(RUNS) * 1.96}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoken = np.zeros(config.total_vocab_size)\n",
    "stoken[config.code_vocab_size+config.label_vocab_size] = 1\n",
    "synthetic_ehr_dataset = []\n",
    "bs = config.sample_batch_size\n",
    "# batch_synthetic_ehrs = sample_sequence(model, config.n_ctx, stoken, batch_size=bs, device=device, sample=True)\n",
    "# batch_synthetic_ehrs = convert_ehr(batch_synthetic_ehrs)\n",
    "# synthetic_ehr_dataset += batch_synthetic_ehrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = bs\n",
    "context = stoken\n",
    "length = config.n_ctx\n",
    "context = torch.tensor(context, device=device, dtype=torch.float32).unsqueeze(0).repeat(batch_size, 1)\n",
    "prev = context.unsqueeze(1)\n",
    "context = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    next = model.sample(prev)\n",
    "    theta = gate(next)\n",
    "    cmpe.set_params(theta)\n",
    "    res = cmpe.get_mpe_inst(next.size(0))\n",
    "    next = (res > 0).float()\n",
    "    prev = torch.cat((prev, next.unsqueeze(1)), dim=1)\n",
    "    \n",
    "    print(torch.sum(torch.sum(prev[:,:,config.code_vocab_size+config.label_vocab_size+1], dim=1).bool().int(), dim=0).item() == batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    next = model.sample(prev)\n",
    "    theta = gate(next)\n",
    "    cmpe.set_params(theta)\n",
    "    res = cmpe.get_mpe_inst(32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sigmoid()[0][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "next = (res > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1611],\n",
       "        [   0, 1614],\n",
       "        [   1, 1611],\n",
       "        [   1, 1614],\n",
       "        [   2, 1611],\n",
       "        [   2, 1614],\n",
       "        [   3, 1611],\n",
       "        [   3, 1614],\n",
       "        [   4, 1611],\n",
       "        [   4, 1614],\n",
       "        [   5, 1611],\n",
       "        [   5, 1614],\n",
       "        [   6, 1611],\n",
       "        [   6, 1614],\n",
       "        [   7, 1611],\n",
       "        [   7, 1614],\n",
       "        [   8, 1611],\n",
       "        [   8, 1614],\n",
       "        [   9, 1611],\n",
       "        [   9, 1614],\n",
       "        [  10, 1611],\n",
       "        [  10, 1614],\n",
       "        [  11, 1611],\n",
       "        [  11, 1614],\n",
       "        [  12, 1611],\n",
       "        [  12, 1614],\n",
       "        [  13, 1611],\n",
       "        [  13, 1614],\n",
       "        [  14, 1611],\n",
       "        [  14, 1614],\n",
       "        [  15, 1611],\n",
       "        [  15, 1614],\n",
       "        [  16, 1611],\n",
       "        [  16, 1614],\n",
       "        [  17, 1611],\n",
       "        [  17, 1614],\n",
       "        [  18, 1611],\n",
       "        [  18, 1614],\n",
       "        [  19, 1611],\n",
       "        [  19, 1614],\n",
       "        [  20, 1611],\n",
       "        [  20, 1614],\n",
       "        [  21, 1611],\n",
       "        [  21, 1614],\n",
       "        [  22, 1611],\n",
       "        [  22, 1614],\n",
       "        [  23, 1611],\n",
       "        [  23, 1614],\n",
       "        [  24, 1611],\n",
       "        [  24, 1614],\n",
       "        [  25, 1611],\n",
       "        [  25, 1614],\n",
       "        [  26, 1611],\n",
       "        [  26, 1614],\n",
       "        [  27, 1611],\n",
       "        [  27, 1614],\n",
       "        [  28, 1611],\n",
       "        [  28, 1614],\n",
       "        [  29, 1611],\n",
       "        [  29, 1614],\n",
       "        [  30, 1611],\n",
       "        [  30, 1614],\n",
       "        [  31, 1611],\n",
       "        [  31, 1614]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr = prev.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateDataset(dataset, rules):\n",
    "  violationsPerRule = []\n",
    "  for (past_visits, past_pos_codes, past_neg_codes, curr_pos_codes, curr_neg_codes, output_code, output_value) in tqdm(rules, leave=False):\n",
    "    violations = 0\n",
    "    for p in tqdm(dataset, leave=False):\n",
    "      visits = [[]] + [[l + config.code_vocab_size for l in p['labels'].nonzero()[0]]] + p['visits']\n",
    "      for i, v in enumerate(visits):\n",
    "        pastSatisfied = False\n",
    "        currSatisfied = False\n",
    "        if not past_visits:\n",
    "          pastSatisfied = True\n",
    "        else:\n",
    "          if past_visits == -1:\n",
    "            past_codes = set([c for v in p['visits'][:i] for c in v])\n",
    "          else:\n",
    "            visit_past_visits = [pi for pi in past_visits if (i > pi if pi >= 0 else i+pi >= 0)]\n",
    "            past_codes = set([c for pi in visit_past_visits for c in (visits[pi] if pi >= 0 else visits[i+pi])])\n",
    "            \n",
    "          if all([c in past_codes for c in past_pos_codes] + [c not in past_codes for c in past_neg_codes]):\n",
    "            pastSatisfied = True\n",
    "        \n",
    "        if all([c in v for c in curr_pos_codes] + [c not in v for c in curr_neg_codes]):\n",
    "          currSatisfied = True\n",
    "          \n",
    "        if pastSatisfied and currSatisfied:\n",
    "          if (output_value and output_code not in v) or (not output_value and output_code in v): \n",
    "            violations += 1\n",
    "    \n",
    "    violationsPerRule.append(violations)\n",
    "  results = {'Per Rule': violationsPerRule, 'Total Number': sum(violationsPerRule)}\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "violations = evaluateDataset(synthetic_ehr_dataset, config.rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014319023609161378"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end - start) / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Per Rule': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  27,\n",
       "  25,\n",
       "  62,\n",
       "  2,\n",
       "  0,\n",
       "  10,\n",
       "  10,\n",
       "  0,\n",
       "  15,\n",
       "  0,\n",
       "  2,\n",
       "  137,\n",
       "  75,\n",
       "  21,\n",
       "  2,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  16,\n",
       "  1,\n",
       "  5,\n",
       "  47,\n",
       "  0,\n",
       "  0,\n",
       "  167,\n",
       "  127,\n",
       "  131,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  114,\n",
       "  0,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'Total Number': 1032}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1], [1610], [], [], [], 972, 0),\n",
       " ([1], [1610], [], [], [], 89, 0),\n",
       " ([1], [1610], [], [], [], 92, 0),\n",
       " ([1], [1610], [], [], [], 93, 0),\n",
       " ([1], [1610], [], [], [], 94, 0),\n",
       " ([1], [1610], [], [], [], 95, 0),\n",
       " ([1], [1610], [], [], [], 162, 0),\n",
       " ([1], [1610], [], [], [], 163, 0),\n",
       " ([1], [1610], [], [], [], 208, 0),\n",
       " ([1], [1610], [], [], [], 230, 0),\n",
       " ([1], [1610], [], [], [], 294, 0),\n",
       " ([1], [1611], [], [], [], 89, 0),\n",
       " ([1], [1611], [], [], [], 90, 0),\n",
       " ([1], [1611], [], [], [], 92, 0),\n",
       " ([1], [1611], [], [], [], 93, 0),\n",
       " ([1], [1611], [], [], [], 94, 0),\n",
       " ([1], [1611], [], [], [], 95, 0),\n",
       " ([1], [1611], [], [], [], 162, 0),\n",
       " ([1], [1611], [], [], [], 163, 0),\n",
       " ([1], [1611], [], [], [], 208, 0),\n",
       " ([1], [1611], [], [], [], 230, 0),\n",
       " ([1], [1611], [], [], [], 294, 0),\n",
       " ([1], [1612], [], [], [], 972, 0),\n",
       " ([1], [1612], [], [], [], 89, 0),\n",
       " ([1], [1612], [], [], [], 92, 0),\n",
       " ([1], [1612], [], [], [], 93, 0),\n",
       " ([1], [1612], [], [], [], 94, 0),\n",
       " ([1], [1612], [], [], [], 95, 0),\n",
       " ([1], [1612], [], [], [], 162, 0),\n",
       " ([1], [1612], [], [], [], 163, 0),\n",
       " ([1], [1612], [], [], [], 208, 0),\n",
       " ([1], [1612], [], [], [], 230, 0),\n",
       " ([1], [1612], [], [], [], 294, 0),\n",
       " ([1], [1613], [], [], [], 2, 0),\n",
       " ([1], [1613], [], [], [], 7, 0),\n",
       " ([1], [1613], [], [], [], 23, 0),\n",
       " ([1], [1613], [], [], [], 29, 0),\n",
       " ([1], [1613], [], [], [], 48, 0),\n",
       " ([1], [1613], [], [], [], 68, 0),\n",
       " ([1], [1613], [], [], [], 72, 0),\n",
       " ([1], [1613], [], [], [], 75, 0),\n",
       " ([1], [1613], [], [], [], 81, 0),\n",
       " ([1], [1613], [], [], [], 103, 0),\n",
       " ([1], [1613], [], [], [], 104, 0),\n",
       " ([1], [1613], [], [], [], 108, 0),\n",
       " ([1], [1613], [], [], [], 113, 0),\n",
       " ([1], [1613], [], [], [], 984, 0),\n",
       " ([1], [1613], [], [], [], 128, 0),\n",
       " ([1], [1613], [], [], [], 996, 0),\n",
       " ([1], [1613], [], [], [], 140, 0),\n",
       " ([1], [1613], [], [], [], 141, 0),\n",
       " ([1], [1613], [], [], [], 142, 0),\n",
       " ([1], [1613], [], [], [], 143, 0),\n",
       " ([1], [1613], [], [], [], 147, 0),\n",
       " ([1], [1613], [], [], [], 154, 0),\n",
       " ([1], [1613], [], [], [], 161, 0),\n",
       " ([1], [1613], [], [], [], 166, 0),\n",
       " ([1], [1613], [], [], [], 169, 0),\n",
       " ([1], [1613], [], [], [], 189, 0),\n",
       " ([1], [1613], [], [], [], 201, 0),\n",
       " ([1], [1613], [], [], [], 1011, 0),\n",
       " ([1], [1613], [], [], [], 233, 0),\n",
       " ([1], [1613], [], [], [], 234, 0),\n",
       " ([1], [1613], [], [], [], 237, 0),\n",
       " ([1], [1613], [], [], [], 240, 0),\n",
       " ([1], [1613], [], [], [], 262, 0),\n",
       " ([1], [1613], [], [], [], 264, 0),\n",
       " ([1], [1613], [], [], [], 1046, 0),\n",
       " ([1], [1613], [], [], [], 268, 0),\n",
       " ([1], [1613], [], [], [], 1052, 0),\n",
       " ([1], [1613], [], [], [], 1055, 0),\n",
       " ([1], [1613], [], [], [], 1098, 0),\n",
       " ([1], [1613], [], [], [], 354, 0),\n",
       " ([1], [1615], [], [], [], 972, 0),\n",
       " ([1], [1615], [], [], [], 108, 0),\n",
       " ([-1], [], [], [688], [], 688, 1),\n",
       " ([], [], [], [1610], [], 1611, 0),\n",
       " ([], [], [], [1610], [], 1612, 0),\n",
       " ([], [], [], [1610], [], 1613, 0),\n",
       " ([], [], [], [1611], [], 1612, 0),\n",
       " ([], [], [], [1611], [], 1613, 0),\n",
       " ([], [], [], [1612], [], 1613, 0),\n",
       " ([], [], [], [1614], [], 1615, 0),\n",
       " ([], [], [], [514], [], 93, 1),\n",
       " ([], [], [], [1196], [], 93, 1),\n",
       " ([], [], [], [1297], [], 1158, 1),\n",
       " ([], [], [], [1366], [], 288, 1)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 10000, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violations['Per Rule'][-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_circuit(model, gate, cmpe, epoch, data_loader, data_split, prefix):\n",
    "\n",
    "    test_val_t = perf_counter()\n",
    "\n",
    "    for i, (x,y) in enumerate(data_loader):\n",
    "\n",
    "        model.eval()\n",
    "        gate.eval()\n",
    "                \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Parameterize circuit using nn\n",
    "        emb = model(x.float())\n",
    "        thetas = gate(emb)\n",
    "\n",
    "        # negative log likelihood and map\n",
    "        cmpe.set_params(thetas)\n",
    "        nll = cmpe.cross_entropy(y, log_space=True).mean()\n",
    "\n",
    "        cmpe.set_params(thetas)\n",
    "        pred_y = (cmpe.get_mpe_inst(x.shape[0]) > 0).long()\n",
    "\n",
    "        pred_y = pred_y.to('cpu')\n",
    "        y = y.to('cpu')\n",
    "\n",
    "        num_correct = (pred_y == y.byte()).all(dim=-1).sum()\n",
    "\n",
    "        if i == 0:\n",
    "            test_correct = num_correct\n",
    "            predicted_test = pred_y\n",
    "            y_test = y\n",
    "        else:\n",
    "            test_correct += num_correct\n",
    "            predicted_test = torch.cat((predicted_test, pred_y), dim=0)\n",
    "            y_test = torch.cat((y_test, y), dim=0)\n",
    "\n",
    "    dt = perf_counter() - test_val_t\n",
    "    y_test = y_test[:,data_split.to_eval]\n",
    "    predicted_test = predicted_test[:,data_split.to_eval]\n",
    "    \n",
    "    accuracy = test_correct / len(y_test)\n",
    "    nll = nll.detach().to(\"cpu\").numpy() / (i+1)\n",
    "    jaccard = jaccard_score(y_test, predicted_test, average='micro')\n",
    "    hamming = hamming_loss(y_test, predicted_test)\n",
    "\n",
    "    print(f\"Evaluation metrics on {prefix} \\t {dt:.4f}\")\n",
    "    print(f\"Num. correct: {test_correct}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Hamming Loss: {hamming}\")\n",
    "    print(f\"Jaccard Score: {jaccard}\")\n",
    "    print(f\"nll: {nll}\")\n",
    "\n",
    "\n",
    "    return {\n",
    "        f\"{prefix}/accuracy\": (accuracy, epoch, dt),\n",
    "        f\"{prefix}/hamming\": (hamming, epoch, dt),\n",
    "        f\"{prefix}/jaccard\": (jaccard, epoch, dt),\n",
    "        f\"{prefix}/nll\": (nll, epoch, dt),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semprola",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
